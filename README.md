# Тематическое моделирование
Для тематического моделирования было решено взять статьи журнала The Cut с 2008 по 2019 год. The Cut — это журнал для женщин, освещающий различные темы такие как: последние тенденции моды или провокационные взгляды на важные вопросы от политики до отношений.

Согласно документации BigARTM вся лингвистическая обработка текстов (лемматизация, токенизация, обнаружение n-грамм и т. д.) должна выполняться вне BigARTM. Поэтому для тематического моделирования была проведена обработка текстовых данных в соответствии со следующими этапами:
1.	Удаление пунктуации;
2.	Удаление слишком редких слов;
3.	Лемматизация;
4.	Удаление стоп-слов;
5.	Удаление цифр, коротких слов, разметки и прочих ненужных символов;
6.	Выделение терминов и словосочетаний.

| <img src="https://github.com/GalReg/topic_modeling/blob/main/img1.jpg" width="600"> | 
|:--:| 
| *Результат предобработки текстовых данных.* |

Однако, такой обработки недостаточно для модели BigARTM. Исходные данные должны быть представлены в специальном формате «vowpal wabbit». Это, так называемый, «мешок слов», где каждая новая строка содержит слова, употребляемые в рамках документа. Эта информация записывается после тега |text. Далее перевод этих данных во внутренний формат библиотеки (пакеты документов, именуемые батчами) осуществлялся с помощью создания объекта класса BatchVectorizer.

Следующим шагом появилась необходимость добавить в нашу модель регуляризаторы. Уверенности в том, какие регуляризаторы использовать, не было, так что путём экспериментов, проб и ошибок был задействован только SmoothSparseThetaRegularizer, то есть разреживание матрицы Θ. SmoothSparseThetaRegularizer может и сглаживать и разреживать матрицу, его действия будут зависеть от того, каким мы зададим его коэффициент регуляризации τ. τ>0 — будет сглаживать, τ<0  — разреживать. 

Таким образом, была создана модель, в которой была создана матрица Φ размером "число слов из нашего словаря" на число тем, она инициализирована случайным образом. Для оценки качества модели была использована перплексия и TopTokensScore — топ 20 слов по каждой тематике. Перплексия — это мультипликативная обратная вероятность, присвоенная тестовому набору языковой моделью, нормированная на количество слов в тестовом наборе. Если языковая модель может предсказать недостающие слова из тестового набора, то такая языковая модель является более точной.

Топ 20 слов по каждой тематике были использованы в дальнейшем для обнаружения уникальных тематик в году. Сравнение происходило в функции add_uniq_topics по количеству пересечений слов в каждой тематике, которое задавалось вручную. Если пересечение слов было больше заданного количества, то тематики считались идентичными. Отрисовку на графике всех уникальных тем в году осуществляла функция find_topics_create_matrix, отображая темы, проявляющиеся в течение длительного непрерывного промежутка времени и краткосрочные темы.

| ![image](https://github.com/GalReg/topic_modeling/blob/main/img2.jpg) | 
|:--:| 
| *Результат оценки TopTokensScore в августе 2018 года.* |

Далее для обучения был использован оффлайновый алгоритм — это много проходов по коллекции, один проход по документу, обновление Φ в конце каждого прохода. Я использовала этот алгоритм, так как он лучше всего подходит для маленьких коллекций, а наше обучение как раз происходило по небольшим коллекциям каждого месяца каждого года в отдельности.
Согласно полученным графикам, можно провести анализ длительности тем. Сокращенный список самых долгосрочных тематик за все года получился таким:
- collection, line, look
- fashion, brand, new
- hair, look, like
- skin, color, foundation
- like, get, eat
- love, relationship, cry
- skin, product, ingredient
- pore, skin, sugar
- price, original, buy
- beauty, look, makeup
- wear, look, dress
- study, happiness, people
- use, vitamin, get

То есть самыми часто и долго обсуждаемыми вопросами в статьях являются мода, уход за кожей или волосами, макияж, покупка чего-либо, отношения, забота о здоровье, учёба. Результаты получились довольно предсказуемыми, так как журнал является женским. Также эксперимент показал, что самыми неустойчивыми являются темы, рассказывающие о какой-то отдельной персоне, событии или важном/интересном сведении, например:
- show, new, cardi
- embryo, abnormal, reiki
- language, group, diversity
- difference, brain, people
- cancer, woman, risk
- princess, get, case
- gaga, lady, one                      и т.д.

Расчёты показали, что в среднем доля долгосрочных тематик составляет 12–15% всех тем за год, а остальные темы являются либо обсуждаемыми единожды, либо появляющимися на короткий срок в разные промежутки времени.

# Заключение
В результате прохождения практики была изучена библиотека BigARTM для тематического моделирования текстов и построена модель для тематического моделирования. Были проведены эксперименты по выявлению долгосрочных и краткосрочных тематик, в ходе которых было выяснено, что самыми долгосрочными, независимо от года, темами являются мода, красота, здоровье, отношения, а самыми краткосрочными являются темы о конкретных людях, событиях, фактах. Также расчёты показали, что в среднем доля долгосрочных тематик составляет 12–15% от всех тем за год.

| ![image](https://github.com/GalReg/topic_modeling/blob/main/img3.jpg) | 
|:--:| 
| *Результат тематического моделирования статей The Cut за 2010 год.* |
